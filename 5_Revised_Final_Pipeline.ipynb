{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " Final.ipynb file should contain the following :\n",
        "\n",
        "    It should have two functions.\n",
        "    Function-1\n",
        "        Should include entire pipeline, from data preprocessing to making final predictions.\n",
        "        It should take in raw data as input.\n",
        "        It should return predictions for your input. Here the input can be a single point or a set of points.\n",
        "        def final_fun_1(X):\n",
        "        .....\n",
        "        .....\n",
        "        ..... # you will use the best model that you found out with your experiments\n",
        "        return predictions made on X ( Raw Data)\n"
      ],
      "metadata": {
        "id": "RLLEmzVZ__rE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UlGOJcoepXm0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing all the necessary libraries"
      ],
      "metadata": {
        "id": "Ueyv_yn0b9iG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import IPython\n",
        "import scipy\n",
        "import datetime\n",
        "import zipfile\n",
        "import joblib\n",
        "import shutil\n",
        "import os\n",
        "import gc\n",
        "from sklearn.metrics import label_ranking_average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style=\"white\")\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.metrics import Metric\n",
        "from tensorflow.keras import Model, optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, Callback \n",
        "from tensorflow.keras.layers import Flatten, Input, Dense\n",
        "from tensorflow.keras.utils import Sequence, to_categorical\n",
        "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2B2\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "tf.random.set_seed(21)\n",
        "np.random.seed(21)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVp8OO9Xb9V5",
        "outputId": "0fbd4fd3-891f-467f-ae94-03607e38f921"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv0Wpd7lQpN3"
      },
      "source": [
        "### Code for the performance metric: LWLRAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sa4-84bfQpN3"
      },
      "outputs": [],
      "source": [
        "# Reference implementation from: https://colab.research.google.com/drive/1AgPdhSp7ttY18O3fEoHOQKlt_3HJDLi8\n",
        "\n",
        "def _one_sample_positive_class_precisions(example):\n",
        "    \"\"\" The function  _one_sample_positive_class_precisions, \n",
        "    takes in an input example consisting of a true \n",
        "    label vector y_true and a predicted label vector y_pred. \n",
        "    \n",
        "    Args: _It  takes in an input example consisting of a true label vector y_true and a predicted label vector y_pred.\n",
        "        \n",
        "    Returns: The resulting dense tensor represents the precision values for each positive class in the input example.\n",
        "    \"\"\"\n",
        "    y_true, y_pred = example\n",
        "    retrieved_classes = tf.argsort(y_pred, direction='DESCENDING')\n",
        "    class_rankings = tf.argsort(retrieved_classes)\n",
        "    retrieved_class_true = tf.gather(y_true, retrieved_classes)\n",
        "    retrieved_cumulative_hits = tf.math.cumsum(tf.cast(retrieved_class_true, tf.float32))\n",
        "\n",
        "    idx = tf.where(y_true)[:, 0]\n",
        "    i = tf.boolean_mask(class_rankings, y_true)\n",
        "    r = tf.gather(retrieved_cumulative_hits, i)\n",
        "    c = 1 + tf.cast(i, tf.float32)\n",
        "    precisions = r / c\n",
        "    dense = tf.scatter_nd(idx[:, None], precisions, [y_pred.shape[0]])\n",
        "    return dense\n",
        "\n",
        "\n",
        "class LWLRAP(Metric):\n",
        "    \"\"\"The custom metric named LWLRAP that extends the Metric class in TensorFlow. \n",
        "    The metric is used to evaluate the performance of a multi-label classification model. \n",
        "    Specifically, it computes the Label-Weighted Average Rank Precision (LWLRAP) score for a batch of predictions and ground truth labels.\n",
        "    precisions and _counts using self.add_weight(). \n",
        "    These variables are used to store the cumulative precision and count for each class in the classification problem.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes, name='lwlrap'):\n",
        "        super().__init__(name=name)\n",
        "\n",
        "        self._precisions = self.add_weight(\n",
        "            name='per_class_cumulative_precision',\n",
        "            shape=[num_classes],\n",
        "            initializer='zeros')\n",
        "\n",
        "        self._counts = self.add_weight(\n",
        "            name='per_class_cumulative_count',\n",
        "            shape=[num_classes],\n",
        "            initializer='zeros')    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utility Functions"
      ],
      "metadata": {
        "id": "M_Bm2fHYcQ6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config():\n",
        "    def __init__(self, sampling_rate, n_classes=80):\n",
        "        self.sampling_rate=sampling_rate\n",
        "        self.n_classes=n_classes\n",
        "        self.stft_window_seconds=0.025\n",
        "        self.stft_hop_seconds=0.010\n",
        "        self.mel_bands=96\n",
        "        self.mel_min_hz=20\n",
        "        self.mel_max_hz=20000\n",
        "        self.mel_log_offset=0.001\n",
        "        self.example_window_seconds=1.0\n",
        "        self.example_hop_seconds=0.5\n",
        "\n",
        "def fetch_map(train_csv_path=None):\n",
        "    \"\"\"\n",
        "    Creates a hash table mapping between each integer from 0-79 and each unique class label.\n",
        "    Args:\n",
        "        train_csv_path (str): Path to the \"train_curated.csv\" file which is used to obtain the list of all class labels.\n",
        "    Returns:\n",
        "        dict: The class mapping hash table where the key is an integer (0-79) and the value is the corresponding\n",
        "        class label.\n",
        "    \"\"\"\n",
        "    # Read the input csv file\n",
        "    df_train = pd.read_csv(train_csv_path)\n",
        "\n",
        "    # Create a set of all unique class labels present in the above file\n",
        "    unique_labels = set(df_train['labels'].str.split(',').explode().unique())\n",
        "\n",
        "    # Sort the set in alphabetical order\n",
        "    sorted_labels = sorted(unique_labels)\n",
        "\n",
        "    # Create the hash table\n",
        "    class_map = {i: label for i, label in enumerate(sorted_labels)}\n",
        "\n",
        "    return class_map\n",
        "\n",
        "def process(clip, clip_dir=None):\n",
        "    \"\"\"Decodes a WAV clip into a batch of log mel spectrum examples.\n",
        "\n",
        "    This function takes the given .wav file, gets its tensor representation, converts it into spectrogram using short-time\n",
        "    Fourier transform, then converts the spectrogram into log mel spectrogram, finally, it divides it into various windows\n",
        "    and returns all the windows in a 3-channel format.\n",
        "\n",
        "    Args:\n",
        "        clip (str): Path to .wav file, e.g., 'file1.wav'.\n",
        "        clip_dir (str, optional): Parent folder in which the above clips is stored, e.g., 'preprocessed_dir'.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Log mel spectrogram windowed features.\n",
        "    \"\"\"\n",
        "    # Decode WAV clip into waveform tensor.   \n",
        "    form_wave = tf.squeeze(tf.audio.decode_wav(tf.io.read_file(clip))[0])\n",
        "\n",
        "    # Convert waveform into spectrogram using a Short-Time Fourier Transform.\n",
        "    # Note that tf.signal.stft() uses a periodic Hann window by default.\n",
        "    window_length_samples = int(round(config.sampling_rate * config.stft_window_seconds))\n",
        "    hop_length_samples = int(round(config.sampling_rate * config.stft_hop_seconds))\n",
        "    fft_length = 2 ** int(np.ceil(np.log2(window_length_samples)))\n",
        "    \n",
        "    magnitude_spectrogram = tf.math.abs(tf.signal.stft(signals=form_wave,\n",
        "                                                       frame_length=window_length_samples,\n",
        "                                                       frame_step=hop_length_samples,\n",
        "                                                       fft_length=fft_length))\n",
        "\n",
        "    # Convert spectrogram into log mel spectrogram.\n",
        "    num_spectrogram_bins = fft_length // 2 + 1\n",
        "    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(num_mel_bins=config.mel_bands,\n",
        "                                                                        num_spectrogram_bins=num_spectrogram_bins,\n",
        "                                                                        sample_rate=config.sampling_rate,\n",
        "                                                                        lower_edge_hertz=config.mel_min_hz,\n",
        "                                                                        upper_edge_hertz=config.mel_max_hz)\n",
        "    mel_spectrogram = tf.matmul(magnitude_spectrogram, linear_to_mel_weight_matrix)\n",
        "    log_mel_spectrogram = tf.math.log(mel_spectrogram + config.mel_log_offset)\n",
        "\n",
        "    # Frame log mel spectrogram into examples.\n",
        "    spectrogram_sr = 1 / config.stft_hop_seconds\n",
        "    example_window_length_samples = int(round(spectrogram_sr * config.example_window_seconds))\n",
        "    example_hop_length_samples = int(round(spectrogram_sr * config.example_hop_seconds))\n",
        "    features = tf.signal.frame(signal=log_mel_spectrogram,\n",
        "                               frame_length=example_window_length_samples,\n",
        "                               frame_step=example_hop_length_samples,\n",
        "                               pad_end=True,\n",
        "                               pad_value=0.0,\n",
        "                               axis=0)\n",
        "    \n",
        "    # Converting mono channel to 3 channels\n",
        "    features = mono_to_color(features)\n",
        "    features=tf.stack([features,features,features], axis=-1)      \n",
        "    return features\n",
        "\n",
        "def mono_to_color(X, mean=None, std=None, norm_max=None, norm_min=None, eps=1e-6):\n",
        "    \"\"\"\n",
        "    Description - The mono_to_color function converts a grayscale image to a colored image. It applies standardization to the input \n",
        "                  data and then normalizes it between the values of norm_min and norm_max. If the difference between the minimum and\n",
        "                  maximum values is greater than eps, it then maps the normalized values to the range [0, 255] to obtain a colored \n",
        "                  image. If the difference is smaller than eps, the function returns a tensor of zeros with the same shape as the \n",
        "                  input tensor. If the mean and std parameters are not provided, the function calculates them from the input tensor.\n",
        "                  If norm_min and norm_max are not provided, the function calculates them from the normalized input tensor. \n",
        "                  The eps parameter is used to avoid division by zero.\n",
        "    \"\"\"    \n",
        "    # Standardize\n",
        "    mean = mean or tf.math.reduce_mean(X)\n",
        "    std = std or tf.math.reduce_std(X)\n",
        "    Xstd = (X - mean) / (std + eps)\n",
        "    _min, _max = tf.math.reduce_min(Xstd), tf.math.reduce_max(Xstd)\n",
        "    norm_max = norm_max or _max\n",
        "    norm_min = norm_min or _min\n",
        "    if (_max - _min) > eps:\n",
        "        # Normalize to [0, 255]\n",
        "        V = Xstd\n",
        "        V = tf.where(V < norm_min, norm_min, V)\n",
        "        V = tf.where(V > norm_max, norm_max, V)\n",
        "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
        "        V = tf.cast(V, tf.float32)\n",
        "    else:\n",
        "        # Just zero\n",
        "        V = tf.zeros_like(Xstd, dtype=tf.float32)\n",
        "    return V   \n",
        "\n",
        "def cnnmodel(weights_path=None):\n",
        "    '''\n",
        "    Description - This function returns a 2D CNN model. \n",
        "    If a \"weights_path\" is provided, it returns the model with the best weights for testing. \n",
        "    If not, it returns the compiled model for training.\n",
        "    '''    \n",
        "    model = EfficientNetV2B2(include_top=False, input_shape=(100, 96, 3))\n",
        "    x = Flatten()(model.layers[-1].output)\n",
        "    out = Dense(80)(x)\n",
        "    model = Model(inputs=model.input, outputs=out)\n",
        "    if not weights_path: \n",
        "        model.compile(optimizer='adam',\n",
        "                      loss=tf.nn.sigmoid_cross_entropy_with_logits,\n",
        "                      metrics=[LWLRAP(80)])\n",
        "    else:\n",
        "        model.load_weights(weights_path)        \n",
        "    return model\n",
        "\n",
        "config = Config(44100)    "
      ],
      "metadata": {
        "id": "IcMGI9epcQKU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function 1"
      ],
      "metadata": {
        "id": "YCCVcOgsbtFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def final_function_1(X):\n",
        "  \"\"\"\n",
        "  Description -> Given a raw audio signal X, this function processes the audio signal into features, \n",
        "                 feeds it to a pre-trained convolutional neural network model, and generates a pandas DataFrame \n",
        "                 containing the top 5 predicted labels and their associated probabilities, sorted in descending order. \n",
        "\n",
        "                  Args:\n",
        "                  - X: A raw audio signal in the form of a numpy array. \n",
        "\n",
        "                  Returns:\n",
        "                  - A pandas DataFrame containing the top 5 predicted labels and their associated probabilities, \n",
        "                    sorted in descending order.\n",
        "  \"\"\"  \n",
        "  features = process(X)\n",
        "  model = cnnmodel(r\"/content/gdrive/MyDrive/modelfreesound3/weights1_8-loss_0.0024_lwlrap_0.9922.h5\")\n",
        "  prediction = np.average((1/(1+np.exp(-model.predict(features)))),axis=0)\n",
        "  prediction_sorted = np.argsort(prediction)\n",
        "  labmap = fetch_map(r'/content/gdrive/MyDrive/Freesound_new/train_curated.csv')\n",
        "  topfive = [labmap[i] for i in prediction_sorted[-5:][::-1]]\n",
        "  topfiveprob = prediction[prediction_sorted[-5:][::-1]]        \n",
        "  result = pd.DataFrame({topfive[i]:topfiveprob[i] for i in range(5)},index=[0])\n",
        "  print(result.to_markdown())"
      ],
      "metadata": {
        "id": "OJif8IqkbaKd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_function_1(r\"/content/gdrive/MyDrive/Freesound_new/train_curated/0164cba5.wav\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOWWXEuU68_D",
        "outputId": "2d09646e-8439-4e37-b64e-881076b4e75b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fce12a8d790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n",
            "|    |   Female_singing |   Child_speech_and_kid_speaking |   Gurgling |   Tick-tock |   Motorcycle |\n",
            "|---:|-----------------:|--------------------------------:|-----------:|------------:|-------------:|\n",
            "|  0 |         0.842104 |                        0.137572 |  0.0421309 |   0.0215646 |    0.0211881 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_function_1(r\"/content/gdrive/MyDrive/Freesound_new/test/4260ebea.wav\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uirIjjov7MGs",
        "outputId": "69bab283-da7b-41b3-8bf3-ad2373cebd65"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n",
            "|    |   Gurgling |   Fill_(with_liquid) |      Hiss |   Bathtub_(filling_or_washing) |   Trickle_and_dribble |\n",
            "|---:|-----------:|---------------------:|----------:|-------------------------------:|----------------------:|\n",
            "|  0 |  0.0780865 |             0.053016 | 0.0374634 |                     0.00324725 |            0.00264976 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_test=pd.read_csv(\"/content/gdrive/MyDrive/Freesound_new/sample_submission.csv\")"
      ],
      "metadata": {
        "id": "jmBCLDlN7zsZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx=0\n",
        "for index, row in a_test.iterrows():\n",
        "  if(idx==10):\n",
        "    break\n",
        "  # check to bypass outlier dropped file dropped file\n",
        "  if(os.path.exists(\"/content/gdrive/MyDrive/Freesound_new/test/\"+str(row['fname'])) ==True):\n",
        "    idx=idx+1\n",
        "    print('Count #' +str(idx))\n",
        "    print('*'*100)\n",
        "    print(row['fname'],'---------', '\\n')\n",
        "    final_function_1(r\"/content/gdrive/MyDrive/Freesound_new/test/\"+str(row['fname']))    \n",
        "    IPython.display.Audio(r\"/content/gdrive/MyDrive/Freesound_new/test/\"+str(row['fname']))\n",
        "    print('*'*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOCM94kEwCii",
        "outputId": "29e76872-86dd-43f1-92ba-bceaaf08fee6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count #1\n",
            "****************************************************************************************************\n",
            "4260ebea.wav --------- \n",
            "\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "|    |   Gurgling |   Fill_(with_liquid) |      Hiss |   Bathtub_(filling_or_washing) |   Trickle_and_dribble |\n",
            "|---:|-----------:|---------------------:|----------:|-------------------------------:|----------------------:|\n",
            "|  0 |  0.0780865 |             0.053016 | 0.0374634 |                     0.00324725 |            0.00264976 |\n",
            "****************************************************************************************************\n",
            "Count #2\n",
            "****************************************************************************************************\n",
            "426eb1e0.wav --------- \n",
            "\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "|    |   Applause |   Cheering |    Crowd |   Clapping |      Bark |\n",
            "|---:|-----------:|-----------:|---------:|-----------:|----------:|\n",
            "|  0 |   0.887863 |    0.78528 | 0.542743 |  0.0817388 | 0.0670694 |\n",
            "****************************************************************************************************\n",
            "Count #3\n",
            "****************************************************************************************************\n",
            "428d70bb.wav --------- \n",
            "\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "|    |     Sigh |   Race_car_and_auto_racing |     Gasp |    Sneeze |   Toilet_flush |\n",
            "|---:|---------:|---------------------------:|---------:|----------:|---------------:|\n",
            "|  0 | 0.577058 |                   0.103562 | 0.086467 | 0.0729184 |      0.0728512 |\n",
            "****************************************************************************************************\n",
            "Count #4\n",
            "****************************************************************************************************\n",
            "4292b1c9.wav --------- \n",
            "\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "|    |   Burping_and_eructation |        Tap |   Chewing_and_mastication |       Meow |       Yell |\n",
            "|---:|-------------------------:|-----------:|--------------------------:|-----------:|-----------:|\n",
            "|  0 |                 0.999993 | 0.00500837 |                0.00421706 | 0.00118853 | 0.00104485 |\n",
            "****************************************************************************************************\n",
            "Count #5\n",
            "****************************************************************************************************\n",
            "429c5071.wav --------- \n",
            "\n",
            "2/2 [==============================] - 3s 150ms/step\n",
            "|    |    Knock |   Drawer_open_or_close |   Bass_drum |   Scissors |      Slam |\n",
            "|---:|---------:|-----------------------:|------------:|-----------:|----------:|\n",
            "|  0 | 0.157203 |              0.0272006 |   0.0194442 |  0.0189139 | 0.0140431 |\n",
            "****************************************************************************************************\n",
            "Count #6\n",
            "****************************************************************************************************\n",
            "42c4e76e.wav --------- \n",
            "\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "|    |   Keys_jangling |   Chirp_and_tweet |   Shatter |   Zipper_(clothing) |     Squeak |\n",
            "|---:|----------------:|------------------:|----------:|--------------------:|-----------:|\n",
            "|  0 |        0.758188 |         0.0434588 | 0.0155348 |          0.00858985 | 0.00774414 |\n",
            "****************************************************************************************************\n",
            "Count #7\n",
            "****************************************************************************************************\n",
            "42cbf9d5.wav --------- \n",
            "\n",
            "2/2 [==============================] - 3s 253ms/step\n",
            "|    |   Sink_(filling_or_washing) |   Water_tap_and_faucet |   Gurgling |   Trickle_and_dribble |     Knock |\n",
            "|---:|----------------------------:|-----------------------:|-----------:|----------------------:|----------:|\n",
            "|  0 |                    0.316159 |               0.277612 |  0.0305929 |             0.0134733 | 0.0134288 |\n",
            "****************************************************************************************************\n",
            "Count #8\n",
            "****************************************************************************************************\n",
            "42f88540.wav --------- \n",
            "\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "|    |   Child_speech_and_kid_speaking |   Female_speech_and_woman_speaking |   Female_singing |   Male_speech_and_man_speaking |     Sneeze |\n",
            "|---:|--------------------------------:|-----------------------------------:|-----------------:|-------------------------------:|-----------:|\n",
            "|  0 |                        0.832326 |                           0.450553 |        0.0531562 |                     0.00767546 | 0.00726953 |\n",
            "****************************************************************************************************\n",
            "Count #9\n",
            "****************************************************************************************************\n",
            "42ff5f3e.wav --------- \n",
            "\n",
            "2/2 [==============================] - 5s 182ms/step\n",
            "|    |   Car_passing_by |   Motorcycle |   Traffic_noise_and_roadway_noise |       Bus |   Accelerating_and_revving_and_vroom |\n",
            "|---:|-----------------:|-------------:|----------------------------------:|----------:|-------------------------------------:|\n",
            "|  0 |         0.162076 |     0.147346 |                          0.110858 | 0.0217799 |                            0.0180952 |\n",
            "****************************************************************************************************\n",
            "Count #10\n",
            "****************************************************************************************************\n",
            "43023d54.wav --------- \n",
            "\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "|    |   Car_passing_by |   Stream |   Applause |   Cheering |   Waves_and_surf |\n",
            "|---:|-----------------:|---------:|-----------:|-----------:|-----------------:|\n",
            "|  0 |         0.190466 | 0.172901 |  0.0306574 |  0.0011186 |      0.000494682 |\n",
            "****************************************************************************************************\n"
          ]
        }
      ]
    }
  ]
}